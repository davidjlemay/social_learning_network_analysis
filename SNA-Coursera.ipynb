{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "Dependencies: numpy 1.17, pandas 0.25\n",
    "\n",
    "userUserNetwork = W; Weighted adjacency matrix, probability user u respond to user v\n",
    "treads = R\n",
    "posts = P : user u, creation t, text x\n",
    "documents = N\n",
    "questionTendency = average; number of questions by total posts by user u in thread r for topic k\n",
    "seeking (question) = S; QuestionTendency * log of 1+posts*length\n",
    "disseminating (answer) = D; 1-Seeking\n",
    "dictionary = X\n",
    "topics = K\n",
    "postTopics (theta) = [0,1]^N*K\n",
    "topicWords = [0,1]^K*X\n",
    "SIDR = phi; proportion of seeking by u on topic k by probability for user v responds to user u on topic k\n",
    "DISR = psi; proportion of disseminating by u on topic k by probability for user u responds to user v on topic k\n",
    "Benefit = B; utility obtained by user u for topic k; seeking*log of prob v to u on topic k\n",
    "alpha = marginal benefit of teaching\n",
    "smoothing = sigma\n",
    "c_S, c_D = tightness parameters\n",
    "step = lambda\n",
    "t = threshold; error\n",
    "\n",
    "Compute User-User Network\n",
    "1-Smooth to ensure user responds to each post at most once\n",
    "QuestionTendency = proportion of questions per topic per thread per weighted-average Q for u\n",
    "\n",
    "Seeking and Dissemination\n",
    "1:Extract forum topics: remove stopwords, urls, stem, lemmatize \n",
    "2:Infer if post is question or answer: first post and; other post or; has question mark or 5W1H or 1G\n",
    "3:Compute S and D\n",
    "\n",
    "Projected Gradient Descent\n",
    "C_s = participation rate for seeking\n",
    "C_d = participation rate for dissemination\n",
    "alpha = learning step\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thread = pd.read_json(r'/home/davidlemay/Documents/social_learning_network_analysis/Coursera MOOCs/courses/designingcities-001/thread250-0',orient='records',typ='series',convert_dates=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thread = {}\n",
    "with open ('/home/davidlemay/Documents/social_learning_network_analysis/Coursera MOOCs/courses/designingcities-001/thread25-0', 'r') as f:\n",
    "    thread = json.loads(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.load(open('/home/davidlemay/Documents/social_learning_network_analysis/Coursera MOOCs/courses/designingcities-001/thread25-0','r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import proxmin as px\n",
    "import json, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Coursera course discussion forum files, concatenate threads\n",
    "directory = r'/home/davidlemay/Documents/social_learning_network_analysis/Coursera MOOCs/courses/designingcities-001/'\n",
    "threads = []\n",
    "for f in os.listdir(directory):\n",
    "    thread = json.load(open(os.path.join(directory,f),'r'))\n",
    "    posts = pd.DataFrame(thread['posts'])['post_text'].dropna()\n",
    "    comments = pd.DataFrame(thread['comments'])\n",
    "    threads.append(posts)\n",
    "    if len(comments) > 0:\n",
    "        comments['post_text'] = comments['comment_text'].dropna()\n",
    "        threads.append(comments)\n",
    "    else:\n",
    "        continue\n",
    "df = pd.concat(threads,ignore_index=True,sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df.loc[10028,'post_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10033\n"
     ]
    }
   ],
   "source": [
    "total_posts = 0\n",
    "for x in threads:\n",
    "    total_posts += len(x)\n",
    "print(total_posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hola Camilo!<br />Si seria interesante!.. estamos hablando para compartir puntos de vista. &nbsp;&nbsp;'"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['post_text'][2066]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.to_datetime(df['post_time'],unit='s')\n",
    "df['new_post_time'] = df['post_time'].transform(lambda x: pd.to_datetime(x,unit='s'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def q_a(x):\n",
    "    qWords = re.compile(r'[\\w\\W]*(who|what|where|when|why|how|\\?)[\\w\\W]*')\n",
    "    if re.search(qWords, x):\n",
    "        return 'question'\n",
    "    else:\n",
    "        return 'answer'\n",
    "        \n",
    "df['q_a'] = df['post_text'].apply(lambda x: q_a(x) if type(x) == str else np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# EdX transforms\n",
    "#df['_id'] = df['_id'].transform(lambda x: x['$oid'])\n",
    "#df['parent_id'] = df['parent_id'].transform(lambda x: x['$oid'] if type(x) == dict else np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EdX transform\n",
    "#df.set_index('_id', inplace=True)\n",
    "#df['parent_author_id'] = pd.Series(df['parent_id'].apply(lambda x: df.loc[x, 'author_id'] if type(x) == str else 0), dtype='Int64')\n",
    "#df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(['thread_id','post_time'],inplace=True)\n",
    "df['parent_id'] = df['user_id'].shift(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['post_text'] = df['post_text'].transform(lambda x: x if type(str) else \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _type : either CommentThread (i.e., initiation) or Comment (i.e., reply)\n",
    "InitiationsReplies = pd.crosstab(df['user_id'], df['q_a'])\n",
    "#InitiationsReplies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/susanli2016/NLP-with-Python/blob/master/LDA_news_headlines.ipynb\n",
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.stem.porter import *\n",
    "import nltk\n",
    "#nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer('english')\n",
    "def lemmatize_stemming(text):\n",
    "    return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v'))\n",
    "\n",
    "def preprocess(text):\n",
    "    result = []\n",
    "    for token in gensim.utils.simple_preprocess(text):\n",
    "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3:\n",
    "            result.append(lemmatize_stemming(token))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5242"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df['post_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(WordNetLemmatizer().lemmatize(gensim.utils.simple_preprocess(df['post_text'][1])[7], pos='v'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gensim.utils.simple_preprocess(df['post_text'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "processed_docs = df['post_text'].map(lambda x: preprocess(x) if type(x) == str else [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24      [welcom, design, citi, thank, student, hope, e...\n",
       "2065    [hola, laura, nombr, camilo, pineda, barranqui...\n",
       "2066    [hola, camilo, seria, interesant, estamo, habl...\n",
       "4952              [love, citi, beauti, movement, chicago]\n",
       "4953                           [amaz, think, jane, jacob]\n",
       "2067    [buena, hora, siguen, llegando, colombiano, es...\n",
       "2068    [singapor, paddi, resid, origin, india, live, ...\n",
       "2069    [nice, singapor, meet, point, lion, citi, smal...\n",
       "2365         [friend, moscow, right, jakarta, nice, meet]\n",
       "2366              [love, mumbai, februari, greet, poland]\n",
       "Name: post_text, dtype: object"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_docs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = gensim.corpora.Dictionary(processed_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dictionary.filter_extremes(no_below=5, no_above=0.5, keep_n=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_corpus = [dictionary.doc2bow(doc) for doc in processed_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5242"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(processed_docs)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "lda_model = gensim.models.LdaMulticore(bow_corpus, num_topics=10, id2word=dictionary, passes=2, workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Words: 0.030*\"nbsp\" + 0.016*\"cours\" + 0.015*\"citi\" + 0.015*\"plan\" + 0.013*\"http\" + 0.009*\"live\" + 0.007*\"thank\" + 0.007*\"href\" + 0.006*\"target\" + 0.006*\"peopl\"\n",
      "Topic: 1 \n",
      "Words: 0.029*\"nbsp\" + 0.017*\"citi\" + 0.014*\"http\" + 0.010*\"design\" + 0.009*\"assign\" + 0.008*\"work\" + 0.008*\"cours\" + 0.007*\"href\" + 0.006*\"peopl\" + 0.006*\"think\"\n",
      "Topic: 2 \n",
      "Words: 0.022*\"grade\" + 0.020*\"nbsp\" + 0.019*\"assign\" + 0.017*\"peopl\" + 0.010*\"sketch\" + 0.009*\"present\" + 0.008*\"plan\" + 0.008*\"mark\" + 0.007*\"review\" + 0.007*\"page\"\n",
      "Topic: 3 \n",
      "Words: 0.031*\"citi\" + 0.028*\"nbsp\" + 0.009*\"like\" + 0.007*\"thank\" + 0.007*\"work\" + 0.007*\"urban\" + 0.006*\"build\" + 0.006*\"http\" + 0.006*\"cours\" + 0.006*\"design\"\n",
      "Topic: 4 \n",
      "Words: 0.102*\"nbsp\" + 0.013*\"citi\" + 0.009*\"span\" + 0.009*\"https\" + 0.008*\"imag\" + 0.007*\"peopl\" + 0.006*\"amazonaw\" + 0.006*\"http\" + 0.006*\"coursera\" + 0.006*\"forum\"\n",
      "Topic: 5 \n",
      "Words: 0.051*\"nbsp\" + 0.017*\"assign\" + 0.015*\"coursera\" + 0.013*\"https\" + 0.010*\"cours\" + 0.009*\"citi\" + 0.007*\"hope\" + 0.007*\"like\" + 0.006*\"good\" + 0.006*\"thank\"\n",
      "Topic: 6 \n",
      "Words: 0.021*\"assign\" + 0.020*\"cours\" + 0.012*\"time\" + 0.011*\"nbsp\" + 0.011*\"grade\" + 0.008*\"http\" + 0.007*\"work\" + 0.007*\"like\" + 0.007*\"certif\" + 0.006*\"think\"\n",
      "Topic: 7 \n",
      "Words: 0.025*\"nbsp\" + 0.013*\"citi\" + 0.007*\"peopl\" + 0.006*\"want\" + 0.006*\"great\" + 0.006*\"problem\" + 0.005*\"assign\" + 0.005*\"imag\" + 0.005*\"work\" + 0.005*\"sketch\"\n",
      "Topic: 8 \n",
      "Words: 0.030*\"nbsp\" + 0.026*\"assign\" + 0.021*\"http\" + 0.015*\"citi\" + 0.011*\"think\" + 0.009*\"design\" + 0.009*\"cours\" + 0.009*\"href\" + 0.008*\"peopl\" + 0.008*\"urban\"\n",
      "Topic: 9 \n",
      "Words: 0.067*\"span\" + 0.032*\"nbsp\" + 0.028*\"data\" + 0.028*\"assign\" + 0.015*\"upload\" + 0.014*\"browser\" + 0.013*\"https\" + 0.013*\"coursera\" + 0.011*\"submit\" + 0.011*\"strong\"\n"
     ]
    }
   ],
   "source": [
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    print('Topic: {} \\nWords: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "topicScores = [lda_model.get_document_topics(x) for x in bow_corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = pd.DataFrame([max(x, key=lambda y: y[1]) for x in topicScores])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.insert(2, 'topics', topics[0])\n",
    "#df.drop('topics', 1)\n",
    "#topics.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5242"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.post_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([                   0,     '_reporter_link',             'topics',\n",
       "          '_user_full_name', '_user_profile_link',        '_user_title',\n",
       "         '_viewer_can_edit',   '_viewer_can_vote',          'anonymous',\n",
       "             'comment_text',            'deleted',                 'id',\n",
       "                  'is_spam',               'link',            'post_id',\n",
       "                'post_text',          'post_time',          'text_type',\n",
       "                'thread_id',         'user_agent',            'user_id',\n",
       "                    'votes',      'new_post_time',                'q_a',\n",
       "                'parent_id'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Create the adjacency matrix using _id for index and column labels\"\"\"\n",
    "userNetwork = pd.crosstab(df.user_id,df.parent_id)\n",
    "idx = userNetwork.columns.union(userNetwork.index)\n",
    "userNetwork = userNetwork.reindex(index=idx, columns=idx, fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "userNetwork = pd.DataFrame(userNetwork.sort_index(axis=0).sort_index(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(584, 584)"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#userNetwork.drop(0, axis=0, inplace=True)\n",
    "#userNetwork.drop(0, axis=1, inplace=True)\n",
    "#userNetwork.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalResponses = userNetwork.sum(axis=1)\n",
    "totalPosts = userNetwork.sum(axis=0).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_UserNetwork = userNetwork*totalResponses/totalPosts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(585, 585)"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_UserNetwork.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0        0.249573\n",
       "4004.0     0.001709\n",
       "4249.0     0.001709\n",
       "9991.0     0.006838\n",
       "37799.0    0.001709\n",
       "dtype: float64"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_UserNetwork.mean(0).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "userTopics = pd.crosstab(df['user_id'], [df['q_a'], df['topics']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>q_a</th>\n",
       "      <th colspan=\"10\" halign=\"left\">answer</th>\n",
       "      <th colspan=\"10\" halign=\"left\">question</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topics</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>44</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4004.0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4249.0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9991.0</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37799.0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "q_a     answer                            question                           \n",
       "topics       0  1  2  3  4  5  6  7  8  9        0  1  2  3  4  5  6  7  8  9\n",
       "user_id                                                                      \n",
       "0.0         64  3  2  9  4  0  1  2  1  2       44  4  0  5  1  1  3  0  0  1\n",
       "4004.0       0  0  0  0  0  0  0  0  0  0        1  0  0  0  0  0  0  0  0  0\n",
       "4249.0       0  0  0  0  0  0  0  0  0  0        1  0  0  0  0  0  0  0  0  0\n",
       "9991.0       4  0  0  0  0  0  0  0  0  0        0  0  0  0  0  0  0  0  0  0\n",
       "37799.0      0  0  0  0  0  0  0  0  0  0        1  0  0  0  0  0  0  0  0  0"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "userTopics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "postTopics = userTopics.sum(0)/userTopics.sum(0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "q_a       topics\n",
       "answer    0         0.365063\n",
       "          1         0.032427\n",
       "          2         0.009414\n",
       "          3         0.078975\n",
       "          4         0.038703\n",
       "          5         0.016213\n",
       "          6         0.010460\n",
       "          7         0.008368\n",
       "          8         0.027197\n",
       "          9         0.008891\n",
       "question  0         0.262029\n",
       "          1         0.020397\n",
       "          2         0.008891\n",
       "          3         0.044456\n",
       "          4         0.020921\n",
       "          5         0.009937\n",
       "          6         0.010983\n",
       "          7         0.003138\n",
       "          8         0.017782\n",
       "          9         0.005753\n",
       "dtype: float64"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "postTopics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "postingTendency = userTopics['question']*postTopics.sum()+userTopics['answer']*postTopics.sum()\n",
    "questionTendency = (userTopics['question']*postTopics.sum())/postingTendency.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>topics</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>0.036697</td>\n",
       "      <td>0.039604</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.021186</td>\n",
       "      <td>0.008772</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.073171</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.035714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4004.0</th>\n",
       "      <td>0.000834</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4249.0</th>\n",
       "      <td>0.000834</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9991.0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37799.0</th>\n",
       "      <td>0.000834</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "topics          0         1    2         3         4     5         6    7  \\\n",
       "user_id                                                                     \n",
       "0.0      0.036697  0.039604  0.0  0.021186  0.008772  0.02  0.073171  0.0   \n",
       "4004.0   0.000834  0.000000  0.0  0.000000  0.000000  0.00  0.000000  0.0   \n",
       "4249.0   0.000834  0.000000  0.0  0.000000  0.000000  0.00  0.000000  0.0   \n",
       "9991.0   0.000000  0.000000  0.0  0.000000  0.000000  0.00  0.000000  0.0   \n",
       "37799.0  0.000834  0.000000  0.0  0.000000  0.000000  0.00  0.000000  0.0   \n",
       "\n",
       "topics     8         9  \n",
       "user_id                 \n",
       "0.0      0.0  0.035714  \n",
       "4004.0   0.0  0.000000  \n",
       "4249.0   0.0  0.000000  \n",
       "9991.0   0.0  0.000000  \n",
       "37799.0  0.0  0.000000  "
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questionTendency.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "#userTopics.columns = userTopics.columns.droplevel(0)\n",
    "disseminating = 1-questionTendency * np.log(1+postingTendency)\n",
    "seeking = questionTendency * np.log(1+postingTendency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>topics</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>0.172160</td>\n",
       "      <td>0.082354</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.057374</td>\n",
       "      <td>0.015717</td>\n",
       "      <td>0.013863</td>\n",
       "      <td>0.117764</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.049511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4004.0</th>\n",
       "      <td>0.000578</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4249.0</th>\n",
       "      <td>0.000578</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9991.0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37799.0</th>\n",
       "      <td>0.000578</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "topics          0         1    2         3         4         5         6    7  \\\n",
       "user_id                                                                         \n",
       "0.0      0.172160  0.082354  0.0  0.057374  0.015717  0.013863  0.117764  0.0   \n",
       "4004.0   0.000578  0.000000  0.0  0.000000  0.000000  0.000000  0.000000  0.0   \n",
       "4249.0   0.000578  0.000000  0.0  0.000000  0.000000  0.000000  0.000000  0.0   \n",
       "9991.0   0.000000  0.000000  0.0  0.000000  0.000000  0.000000  0.000000  0.0   \n",
       "37799.0  0.000578  0.000000  0.0  0.000000  0.000000  0.000000  0.000000  0.0   \n",
       "\n",
       "topics     8         9  \n",
       "user_id                 \n",
       "0.0      0.0  0.049511  \n",
       "4004.0   0.0  0.000000  \n",
       "4249.0   0.0  0.000000  \n",
       "9991.0   0.0  0.000000  \n",
       "37799.0  0.0  0.000000  "
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seeking.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = .001\n",
    "alpha = .4\n",
    "beta = 0.8\n",
    "c_S = 1.25\n",
    "c_D = 0.75\n",
    "step = 0.1\n",
    "rho = 1\n",
    "N = w_UserNetwork.shape[0]\n",
    "z1 = lambda1 = np.zeros(seeking.T.shape).astype('float64')\n",
    "z2 = lambda2 = np.zeros(disseminating.shape).astype('float64')\n",
    "W = W_hat = W_obs = w_UserNetwork.fillna(0).astype('float64').to_numpy()\n",
    "W_opt = W_prime = np.zeros(W.shape)\n",
    "D = disseminating.fillna(0).astype('float64').to_numpy()\n",
    "S = seeking.fillna(0).astype('float64').to_numpy()\n",
    "\n",
    "def SIDR(s,d,w):\n",
    "    phi = np.zeros(s.shape)\n",
    "    for u in range(0, s.shape[0]):\n",
    "        for k in range(0, s.shape[1]):\n",
    "            phi[u,k] = s[u,k]/1+(w[:,u].sum()*d[:,k].sum())\n",
    "    return phi\n",
    "\n",
    "def DISR(s,d,w):\n",
    "    psi = np.zeros(d.shape)\n",
    "    for u in range(0, d.shape[0]):\n",
    "        for k in range(0, d.shape[1]):\n",
    "            psi[u,k] = d[u,k]/1+(w[u,:].sum()*s[:,k].sum())\n",
    "    return psi\n",
    "    \n",
    "#SIDR.replace(to_replace=0,value=1)\n",
    "#DISR.replace(to_replace=0,value=1)\n",
    "P = (S/(1+(c_S*SIDR(S,D,W)))).T\n",
    "Q = (D/(1+(c_D*DISR(S,D,W))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations: 2\n",
      "Observed learning benefit: 2.7070190253010744\n",
      "Optimized learning benefit: 22.026077479222476\n"
     ]
    }
   ],
   "source": [
    "np.seterr(all=\"raise\")\n",
    "\n",
    "def benefit(X):\n",
    "    b = np.zeros(D.shape)\n",
    "    for u in range(0, D.shape[0]):\n",
    "        for k in range(0, D.shape[1]):\n",
    "            b[u,k] = (S[u,k]*np.log(1+X[:,u].sum()*D[:,k].sum()) + alpha*D[u,k]*np.log(1+X[u,:].sum()*S[:,k].sum()))\n",
    "    return b\n",
    "\n",
    "def proj(X):\n",
    "    \"\"\"Projection step\"\"\"\n",
    "    return np.clip(np.subtract(X,np.diag(np.diag(X))),0,1)\n",
    "    \n",
    "def grad(X):\n",
    "    \"\"\"Proximal gradient step\"\"\"\n",
    "    return (np.add((rho*np.dot(D,(np.add(np.subtract(np.dot(D.T,X),P),np.subtract(z1,lambda1))))),\n",
    "            (rho*np.dot((np.subtract(np.subtract(np.dot(X,S),Q),np.add(z2,lambda2))),S.T))))\n",
    "\n",
    "g = benefit(W).sum().sum()\n",
    "g_hat = 1\n",
    "i = 0\n",
    "\n",
    "while (g - g_hat)/np.abs(g_hat) >= threshold:\n",
    "    i += 1\n",
    "    for u in range(0, W.shape[0]):\n",
    "        for v in range(0, W.shape[1]):\n",
    "            W_prime[u,v] = (\n",
    "                (D[u].sum()*S[v].sum()/(1+(W[:,v].sum()*D.sum().sum()))\n",
    "                +alpha*D[u].sum()*S[v].sum()/(1+(W[u,:].sum()*S.sum().sum())))\n",
    "                /N\n",
    "            )\n",
    "    W_hat = (W + step * W_prime)\n",
    "    W = proj(grad(W_hat))\n",
    "    g_hat = g\n",
    "    g = benefit(W).sum().sum()\n",
    "    z1 = np.clip(np.add(np.add((-1*np.dot(D.T,W)),P),lambda1),None,0)\n",
    "    z2 = np.clip(np.add(np.subtract(np.dot(W,S),Q),lambda2),None,0)\n",
    "    lambda1 -= np.subtract(np.add(np.dot(D.T,W),P),z1)\n",
    "    lambda2 += np.subtract(np.subtract(np.dot(W,S),Q),z2)\n",
    "    step *= beta\n",
    "\n",
    "print(\"Iterations: \"+str(i))\n",
    "print(\"Observed learning benefit: \"+str(benefit(W_obs).sum().sum()/N))\n",
    "print(\"Optimized learning benefit: \"+str(g_hat/N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import linalg as la"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(la.eig(W_obs)[0]).real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(la.eig(W)[0]).real"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
